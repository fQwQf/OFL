exp_name: "Tiny_alpha0.5"
dataset:
  data_name: "Tiny-ImageNet" # choice: [CIFAR10, CIFAR100, MNIST, FMNIST, Tiny-ImageNet]
  root_path: "~/datasets/"
  # root_path: 'H:/codes/dataset'
  train_batch_size: 256
  test_batch_size: 256
  channels: 3
  num_classes: 200
  image_size: 64 # [CIFAR: 32, MNIST: 28]

  aux_data_name: "Tiny-ImageNet"
  aux_root_path: "~/datasets/"
  # aux_root_path: "H:/codes/dataset"
  aux_split: 'test'

distribution:
  type: "dirichlet" # choice: [iid, noniid, dirichlet]
  label_num_per_client: 2 # non-iid parameter
  alpha: 0.5 # dirichlet distribution parameter

client:
  num_clients: 5

server:
  num_rounds: 10
  frac_clients: 1.0
  lr: 0.05
  local_epochs: 5
  optimizer: "sgd" # choice: [sgd, adam]
  momentum: 0.9
  weight_decay: 0.0001
  loss_name: "ce" # choice: [ce, mse, nll]
  model_name: "resnet18"
  aggregated_by_datasize: True
  lr_decay_per_round: 0.998

device: "cuda:0"

checkpoint:
  save_path: "./checkpoints/"
  save_freq: 5
  result_file: "CIFAR10_results.yaml"

pretrain:
  lr: 0.01
  epoch: 70
  model_path: "./pretrain/"
  momentum: 0.9
  weight_decay: 0.0001
  model_name: "resnet18"
  model_file_name: "resnet18-f37072fd.pth"

DBCD:
  alpha_l_pa: 1
  alpha_l_pb: 1
  alpha_l_pc: 0.0
  Beta_alpha: 0.2
  unsup_method: 'infonce'
  contrastive_temperature: 0.5
  encoder_epoch: 40
  projector_epoch: 10
  use_pretrain: False
  aug_batch_size: 512
  encoder_lr: 0.03
  cls_optimizer: 'sgd'
  cls_lr: 0.05
  supcon_temp: 0.07
  super_gr: 100
  aux_with_public: True

etf:
  loss_name: "ce" # choice: [ce, balanced]

visualization:
  interval: 5
  save_path: 'visualization/resnet18'
  vis_size: 16
resume: True
resume_best: False
seed: 1

lambda_align_initial: 5.0